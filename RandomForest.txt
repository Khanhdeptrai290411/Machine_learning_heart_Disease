# Import các thư viện cần thiết
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve, average_precision_score, log_loss, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
import joblib

# Đặt random seed để đảm bảo kết quả có thể tái hiện
np.random.seed(42)

# Bước 1: Chuẩn bị dữ liệu
# Đọc dữ liệu từ file CSV
dataset = pd.read_csv("/kaggle/input/cardiovascular-disease-dataset/Cardiovascular_Disease_Dataset.csv")

# Loại bỏ cột patientid vì không mang giá trị dự đoán
dataset = dataset.drop('patientid', axis=1)

# Xử lý giá trị bất thường trong cột slope (dựa trên phân tích trước: slope chỉ từ 0-2)
print("Giá trị duy nhất của slope trước khi xử lý:", dataset["slope"].unique())
dataset["slope"] = dataset["slope"].replace(3, 2)  # Thay giá trị 3 bằng 2
print("Giá trị duy nhất của slope sau khi xử lý:", dataset["slope"].unique())

# Kiểm tra giá trị thiếu
print("Kiểm tra giá trị thiếu trong dataset:")
print(dataset.isnull().sum())

# Tách features (X) và target (y)
X = dataset.drop('target', axis=1)
y = dataset['target']

# Bước 2: Tiền xử lý
# Chia dữ liệu thành tập huấn luyện và tập kiểm tra (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Chuẩn hóa dữ liệu (scaling) - cần thiết cho Random Forest trong một số trường hợp
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Chỉ fit trên tập huấn luyện
X_test_scaled = scaler.transform(X_test)  # Chỉ transform trên tập kiểm tra

# Kiểm tra phân bố lớp trong tập kiểm tra
print("Phân bố lớp trong tập kiểm tra:")
print(y_test.value_counts())
# Khởi tạo mô hình Random Forest
rf = RandomForestClassifier(
    n_estimators=50,       # Số lượng cây
    max_depth=5,           # Độ sâu tối đa của cây
    min_samples_split=5,   # Số mẫu tối thiểu để chia nhánh
    min_samples_leaf=2,    # Số mẫu tối thiểu ở lá
    random_state=42
)

# Đo thời gian huấn luyện
start_time = time.time()
rf.fit(X_train_scaled, y_train)
training_time = time.time() - start_time

print(f"Thời gian huấn luyện Random Forest: {training_time:.2f} giây")
# Bước 3: Áp dụng 5-fold Cross Validation
# Định nghĩa các chỉ số cần tính
scoring = ['accuracy', 'precision', 'recall', 'f1']

# Thực hiện Cross-Validation
cv_results = cross_validate(rf, X_train_scaled, y_train, cv=5, scoring=scoring, return_train_score=False)

# Bước 4: Tính trung bình và độ lệch chuẩn cho các chỉ số
metrics = {
    "Accuracy": cv_results['test_accuracy'].mean(),
    "Accuracy Std": cv_results['test_accuracy'].std(),
    "Precision": cv_results['test_precision'].mean(),
    "Precision Std": cv_results['test_precision'].std(),
    "Recall": cv_results['test_recall'].mean(),
    "Recall Std": cv_results['test_recall'].std(),
    "F1": cv_results['test_f1'].mean(),
    "F1 Std": cv_results['test_f1'].std(),
    "Training Time (s)": training_time
}

# Dự đoán trên tập kiểm tra để tính thêm Log Loss
y_pred = rf.predict(X_test_scaled)
y_prob = rf.predict_proba(X_test_scaled)[:, 1]  # Xác suất lớp dương
metrics["Log Loss"] = log_loss(y_test, y_prob)

# Hiển thị kết quả dưới dạng bảng
results_df = pd.DataFrame(metrics, index=["Random Forest"])
print("\n=== Kết quả đánh giá Random Forest (5-fold Cross Validation) ===")
print(results_df)

=== Kết quả đánh giá Random Forest (5-fold Cross Validation) ===
               Accuracy  Accuracy Std  Precision  Precision Std    Recall  \
Random Forest     0.955      0.016956   0.959276       0.017101  0.963347   

               Recall Std        F1    F1 Std  Training Time (s)  Log Loss  
Random Forest    0.016006  0.961244  0.014531           0.078264  0.116877  
# Đánh giá trên tập kiểm tra
train_pred = rf.predict(X_train_scaled)
train_accuracy = accuracy_score(y_train, train_pred)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy trên tập huấn luyện: {train_accuracy:.4f}")
print(f"Accuracy trên tập kiểm tra: {test_accuracy:.4f}")
Accuracy trên tập huấn luyện: 0.9762
Accuracy trên tập kiểm tra: 0.9750
# Vẽ Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Không bệnh", "Có bệnh"], yticklabels=["Không bệnh", "Có bệnh"])
plt.title("Confusion Matrix của Random Forest")
plt.xlabel("Dự đoán")
plt.ylabel("Thực tế")
plt.show()
# Vẽ ROC Curve
plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Random Forest')
plt.legend(loc="lower right")
plt.show()
# Vẽ Precision-Recall Curve
plt.figure(figsize=(8, 6))
precision, recall, _ = precision_recall_curve(y_test, y_prob)
ap_score = average_precision_score(y_test, y_prob)  # Sửa: Dùng y_prob thay vì y_pred
plt.plot(recall, precision, color='purple', lw=2, label=f'Precision-Recall curve (AP = {ap_score:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for Random Forest')
plt.legend(loc="lower left")
plt.show()
# Lưu mô hình Random Forest
model_filename = "/kaggle/working/random_forest_model.pkl"
joblib.dump(rf, model_filename)
print(f"✅ Mô hình Random Forest đã được lưu tại: {model_filename}")